import streamlit as st
from streamlit_option_menu import option_menu
import pandas as pd
from sklearn import datasets 
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import RidgeClassifier, LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, precision_score
import plotly.express as px
import plotly.figure_factory as ff
import streamlit.components.v1 as components
import json
from streamlit_lottie import st_lottie
import requests 

   
# Charger un jeu de donn√©es (exemple avec iris)
iris = datasets.load_iris()
X_train, X_test, y_train, y_test = train_test_split(
    iris.data, iris.target, test_size=0.2, random_state=42
)
# Fonction pour entra√Æner et √©valuer le mod√®le s√©lectionn√©
def evaluate_model(model_name, model, X_train, X_test, y_train, y_test, **kwargs):
    st.success(f"Vous avez choisi le mod√®le : {model_name}")

    # Ajuster les hyperparam√®tres sp√©cifiques au mod√®le s√©lectionn√©
    if model_name == "Random Forest":
        model.set_params(n_estimators=kwargs.get("n_estimators", 100),
                         max_depth=kwargs.get("max_depth", None),
                         min_samples_split=kwargs.get("min_samples_split", 2),
                         min_samples_leaf=kwargs.get("min_samples_leaf", 1))
    elif model_name == "SVM":
        model.set_params(C=kwargs.get("C", 1.0),
                         kernel=kwargs.get("kernel", "rbf"))

    # Entra√Æner le mod√®le
    model.fit(X_train, y_train)

    # Faire des pr√©dictions
    y_pred = model.predict(X_test)

    # creation des colonnes
    c1,c2=st.columns(2)
    # Afficher les m√©triques
    accuracy = accuracy_score(y_test, y_pred)
    c1.info(f"Pr√©cision : {accuracy:.2f}")
    # Utiliser Plotly Express pour afficher la matrice de confusion en tant que heatmap interactif
    
    
    cm = confusion_matrix(y_test, y_pred)

    fig = ff.create_annotated_heatmap(
    z=cm,
    x=["Setosa", "Versicolor", "Virginica"],
    y=["Setosa", "Versicolor", "Virginica"],
    colorscale="Blues",
)

    # Ajouter le texte avec le nombre d'instances dans chaque cellule
    for i in range(len(cm)):
        for j in range(len(cm[i])):
            fig.add_annotation(
                x=j,
                y=i,
                text=str(cm[i][j]),
                showarrow=False,
                font=dict(size=10),
            )

    # Mise en page
    fig.update_layout(
        title=dict(text="Matrice de Confusion", font=dict(color="White"),y=0.95),
        width=300,
        height=220,
        margin=dict(l=0, r=0, b=0, t=60),
    )

    # Afficher la figure
    c1.plotly_chart(fig)

    c2.info("Pr√©diction de la classe")
    with c2:
        col1,col2=st.columns(2)
        param1 = col1.slider("Longueur du s√©pale", min_value=min(iris.data[:, 0]), max_value=max(iris.data[:, 0]), value=iris.data[:, 0].mean())
        param2 = col1.slider("Largeur du s√©pale", min_value=min(iris.data[:, 1]), max_value=max(iris.data[:, 1]), value=iris.data[:, 1].mean())
        param3 = col2.slider("Longueur du p√©tale", min_value=min(iris.data[:, 2]), max_value=max(iris.data[:, 2]), value=iris.data[:, 2].mean())
        param4 = col2.slider("Largeur du p√©tale", min_value=min(iris.data[:, 3]), max_value=max(iris.data[:, 3]), value=iris.data[:, 3].mean())
        # Utiliser les valeurs des sliders pour faire une pr√©diction
        prediction_flowers = model.predict([[param1, param2, param3, param4]])

    # Afficher la classe pr√©dite en fonction de la valeur
    if prediction_flowers[0] == 0:
        c2.success("Classe pr√©dite : Setosa")
    elif prediction_flowers[0] == 1:
        c2.success("Classe pr√©dite : Versicolor")
    elif prediction_flowers[0] == 2:
        c2.success("Classe pr√©dite : Virginica")


with st.sidebar:
    selected = option_menu("Main Menu", ["Home","Mod√®le", 'Settings'], 
        icons=['house', 'gear'], menu_icon="cast", default_index=0)
    
if selected == "Home" or selected is None : 
    st.write("# Welcome ! üëã")

    st.markdown(
       
       "Cette application vous offre la possibilit√© de choisir parmi plusieurs mod√®les de machine learning. "
    "Vous pourrez explorer et analyser les performances de chaque mod√®le en affichant des m√©triques telles que la pr√©cision, "
    "et visualiser la matrice de confusion pour √©valuer sa capacit√© √† faire des pr√©dictions pr√©cises."
)
    
    url = requests.get( 
        "https://lottie.host/7a447ab7-8427-48dc-8dab-544eef7ccff4/EK5ucNy81A.json") 
    # Creating a blank dictionary to store JSON file, 
    # as their structure is similar to Python Dictionary 
    url_json = dict() 
    
    if url.status_code == 200: 
        url_json = url.json() 
        st_lottie(url_json, 
        reverse=True, 
        height=400, 
        width=600, 
        speed=1, 
        loop=True, 
        quality='high'
        )
    else: 
        print("Error in the URL") 
    
    
     
    
     
elif selected == "Mod√®le":
    st.header("Choisissez un mod√®le")

    # Liste des mod√®les disponibles
    models = {
        "Random Forest": RandomForestClassifier(),
        "SVM": SVC(probability=True),
        "M√©thode Bay√©sienne": GaussianNB(),
        "Ridge": RidgeClassifier(),
        "R√©gression Logistique": LogisticRegression()
    }

    # S√©lectionner le mod√®le
    selected_model = st.sidebar.selectbox("S√©lectionnez le mod√®le", list(models.keys()))

    # Ajouter des sliders pour ajuster les hyperparam√®tres sp√©cifiques √† chaque mod√®le
    
    if selected_model == "Random Forest":
        st.sidebar.subheader("Ajustement des Hyperparam√®tres")
        # Ajuster le nombre d'estimateurs (n_estimators)
        n_estimators = st.sidebar.slider("Nombre d'estimateurs ", min_value=1, max_value=100, value=10)

        # Ajuster la profondeur maximale (max_depth)
        max_depth = st.sidebar.slider("Profondeur maximale", min_value=1, max_value=20, value=5)

        # Ajuster le nombre minimal d'√©chantillons pour la division (min_samples_split)
        min_samples_split = st.sidebar.slider("min_samples_split", min_value=2, max_value=20, value=2)

        # Ajuster le nombre minimal d'√©chantillons dans une feuille (min_samples_leaf)
        min_samples_leaf = st.sidebar.slider("min_samples_leaf", min_value=1, max_value=20, value=1)

        # Cr√©er un dictionnaire d'hyperparam√®tres pour le mod√®le Random Forest
        hyperparameters = {
            "n_estimators": n_estimators,
            "max_depth": max_depth,
            "min_samples_split": min_samples_split,
            "min_samples_leaf": min_samples_leaf
        }
        evaluate_model(selected_model, models[selected_model], X_train, X_test, y_train, y_test, **hyperparameters)
    elif selected_model == "SVM":
        st.sidebar.subheader("Ajustement des Hyperparam√®tres SVM")
        # Ajuster le param√®tre de r√©gularisation (C)
        C = st.sidebar.slider("R√©gularisation (C)", min_value=0.1, max_value=10.0, value=1.0)

        # Ajuster le noyau (kernel)
        kernel = st.sidebar.selectbox("Noyau", ["linear", "poly", "rbf", "sigmoid"], index=2)

        # Ajuster d'autres hyperparam√®tres sp√©cifiques au SVM si n√©cessaire

        # Cr√©er un dictionnaire d'hyperparam√®tres pour le mod√®le SVM
        hyperparameters_svm = {
            "C": C,
            "kernel": kernel
            # Ajoutez d'autres hyperparam√®tres sp√©cifiques au SVM si n√©cessaire
        }
        evaluate_model(selected_model, models[selected_model], X_train, X_test, y_train, y_test, **hyperparameters_svm)
    else:
    # Entra√Æner et √©valuer le mod√®le s√©lectionn√© avec les hyperparam√®tres ajust√©s
        evaluate_model(selected_model, models[selected_model], X_train, X_test, y_train, y_test)

